import pandas as pd
import numpy as np
from . import dataset_helpers as dsh
from dlsd import Common as c

def sqlToNumpy_allSensorsInAllOutWithTimeOffset(inputFile,
                                                outputFilePath, 
                                                saveOutputFile = False, 
                                                timeOffset = 15, 
                                                sensorEfficiency = .98):
    '''
        Creates data from SQL output for using in machine learning model. (input/output contained in one row)
        Long/narrow dataset from SQL is made wide (one column per sensor, time stamps are rows)
        Then the table is doubled and concatenated to itself, offset by time (timeOffset)

        Original found in analysis > 10_16 > 24_10_sqlToNumpy_allInputallOutput_timeOffset

        Results in a table where each row has inpu
        

        Args : 
            inputFile :         Path to csv file generated by sql. CSV contains 3 columns 
                                (sensor name, time stamp, value (eg belegung))
            outputFilePath :        Path to output file.
            saveOutputFile :          Boolean, if True the file is written to outputFile
            timeOffset :        Int value of minutes offset between input/output
        Return :
            theData :       FullDataSet object from dataset_helpers containing two DataSet 
                            objects containing two numpy arrays(input/target)
    '''
    all_data = pd.read_csv(inputFile,sep=",")
    c.debugInfo(__name__,"Read input SQL file with shape : (%d, %d)"%(all_data.shape[0],all_data.shape[1]))

    data_wide_all = all_data.pivot(index='ZEIT', columns='S_IDX', values='wert')
    c.debugInfo(__name__,"Pivoted input shape : (%d, %d)"%(data_wide_all.shape[0],data_wide_all.shape[1]))

    # make table containing only efficient sensors (only columns with efficiency >sensorEfficiency nan are used)

    #count the number of times each column has an 'na' value
    counts = np.zeros((data_wide_all.shape[1],1))
    for i in range(0,data_wide_all.shape[1]):
        counts[i] = len(np.where(np.isnan(data_wide_all.iloc[:,i]))[0])

    # calculate the efficiency of the sensor
    sensorsToEfficiency = pd.DataFrame(np.zeros((3,counts.shape[0])))
    sensorsToEfficiency.iloc[0,:]=data_wide_all.columns.values.reshape(1,-1)
    sensorsToEfficiency.iloc[2,:]=1-counts.reshape(1,-1)/(data_wide_all.shape[0])
    sensorsToEfficiency.iloc[1,:]=counts.reshape(1,-1)
    
    # make table containing only efficient sensors (only columns with <10 nan are used)
    efficientSensorIndices = np.where(sensorsToEfficiency.iloc[2,:].values>sensorEfficiency)
    data_wide = data_wide_all.iloc[:,efficientSensorIndices[0]]
    data_wide.shape
    c.debugInfo(__name__,"Data where sensors have efficiency > %.2f : (%d, %d)"%(sensorEfficiency,data_wide.shape[0],data_wide.shape[1]))
    c.debugInfo(__name__,"There are %d sensors in total, but only %d have efficiency > %.2f"%(data_wide_all.shape[1], data_wide.shape[1],sensorEfficiency))

    # each row has two time points for example :
    # [All sensors at timepoint 0] [All sensors at timepoint 0+timeOffset]
    # set the offset time to 'output'

    # make empty data frame to fit this data
    newShape = (data_wide.shape[0]+timeOffset,data_wide.shape[1]*2)

    # create empty array filled with nan
    data_final = pd.DataFrame(np.zeros(newShape))
    data_final[:] = np.NAN

    # first fill 'input' data
    data_final.iloc[0:data_wide.shape[0],0:data_wide.shape[1]] = data_wide.iloc[0:data_wide.shape[0],0:data_wide.shape[1]].values

    # then fill 'output' data : time at x + timeOffset
    data_final.iloc[timeOffset:data_wide.shape[0]+timeOffset,data_wide.shape[1]:2*data_wide.shape[1]] = data_wide.iloc[:,0:data_wide.shape[1]].values

    # set column names
    colNames = data_wide.columns.values.reshape(1,-1)
    colNames_final = np.concatenate((colNames,colNames),axis=1)
    data_final.columns = colNames_final[0,:]

    # drop all rows with NaN somewhere
    c.debugInfo(__name__,"Removing rows with >0 NaNs")
    data_final_naDropped = data_final.dropna()
    c.debugInfo(__name__,"From %d total timepoints, %d are being used (%.2f)"%(data_wide_all.shape[0],data_final_naDropped.shape[0],(data_final_naDropped.shape[0]/data_wide_all.shape[0])))

    #data_final.to_csv("/Users/ahartens/Desktop/Temporary/24_10_16_wideTimeSeriesBelegung.csv")
    if (saveOutputFile == True):
        c.debugInfo(__name__,"Saving processed file to %s"%(outputFilePath))
        data_final_naDropped.to_csv(outputFilePath,index=False)

    return data_final_naDropped
